\section{Variable Description and Nouns Interpretation}

\subsection{Variable Description}
%table
\begin{tabular}{|c|c|}
\hline 
Variable&Description\\
\hline  
$I(E)$ & Self-information about an event of non-trival probality\\
\hline 
$Pr(E)$ & Probabilty of an event\\
\hline
$H(X)$ & Entropy(Information Theory)\\
\hline
$E(X)$ & the mathematical expectation\\
\hline
\end{tabular}
\subsection{Nouns Interpretation}
\begin{enumerate}[(1)]
\item Self-information: the amount of information obtained during sampling
\item Entropy: the mathemetical expectation of self-information
\item Conditional Entropy: the entropy of a random variable Y based on the value of another random variable X is known
\item Abusolute Rule: describe the position of a kind of animal
\item Relative Rule: describe the position relationship between the two animal
\item Rule Network / Rule Library: the set to store the "map" and all the rules including existing rules and updated rules
\item Thinking Energy Cost: the energy required to perform each operation
\item Status: the combination of the updated "map" and the updated Rule Network / Rule Library
%\item

\end{enumerate}
\section{Model Assumption}
\begin{enumerate}[(1)]
\item Considering the benefit of the whole solving process, Certian Absolute Rules, whether they'll derive the most entropy decrease, has the highest priorities.
\item People's thinking pattern is parallel rather than serial, we put this point into consideration while determining the complexity and the Thinking Energy Cost of each step in problem solving.
\end{enumerate}
